{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453e1bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 19:23:17.917094: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6401aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = Sequential([\n",
    "    layers.Flatten(input_shape=(28,28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699a2d88",
   "metadata": {},
   "source": [
    "In a **functional API** layout, we follow the next 3 steps in order to define our model:\n",
    " - 1) Input: define input to the model\n",
    " - 2) Layers: define a set of interconnected layers on the input\n",
    " - 3) Model: define the model using the input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed3a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b491e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e38cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b24ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(input)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8320e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe50afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = Model(inputs = input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38450592",
   "metadata": {},
   "source": [
    "## Branching models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c2fc26",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got '<keras.layers.core.dense.Dense object at 0x167ef8be0>' (of type <class 'keras.layers.core.dense.Dense'>) as input for layer 'dense_5'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m layer1 \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m layer2_1 \u001b[38;5;241m=\u001b[39m \u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m layer2_2 \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m32\u001b[39m)(layer1)\n\u001b[1;32m      4\u001b[0m layer2_3 \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m32\u001b[39m)(layer1)\n",
      "File \u001b[0;32m~/Documents/toelt_venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/toelt_venv/lib/python3.8/site-packages/keras/engine/input_spec.py:213\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) as input for layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got '<keras.layers.core.dense.Dense object at 0x167ef8be0>' (of type <class 'keras.layers.core.dense.Dense'>) as input for layer 'dense_5'."
     ]
    }
   ],
   "source": [
    "layer1 = Dense(32)\n",
    "layer2_1 = Dense(32)(layer1)\n",
    "layer2_2 = Dense(32)(layer1)\n",
    "layer2_3 = Dense(32)(layer1)\n",
    "layer2_4 = Dense(32)(layer1)\n",
    "merge = Concatenate([layer2_1,layer2_2,layer2_3,layer2_4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c5702",
   "metadata": {},
   "source": [
    "## Creating a multi-output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "430c6dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          1152        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 128)          16512       ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 64)           8256        ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " y1_output (Dense)              (None, 1)            129         ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " y2_output (Dense)              (None, 1)            65          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,114\n",
      "Trainable params: 26,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(len(train.columns),))\n",
    "first_dense = Dense(units='128', activation='relu')(input_layer)\n",
    "second_dense = Dense(units='128',activation='relu')(first_dense)\n",
    "\n",
    "y1_output = Dense(units='1', name='y1_output')(second_dense)\n",
    "third_dense = Dense(units='64', activation='relu')(second_dense)\n",
    "y2_output = Dense(units='1', name='y2_output')(third_dense)\n",
    "\n",
    "\n",
    "# define the model with the input layer and a list of output layers\n",
    "model = Model(inputs=input_layer, outputs=[y1_output,y2_output])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a2912",
   "metadata": {},
   "source": [
    "## prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f854202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "import pandas as pd\n",
    "import pydot\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"/Users/sonic/Documents/playing/tf_advanced_techniques_specialization/ENB2012_data.xlsx\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split the dataset\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train_stats = train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23c58d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(data):\n",
    "    y1 = data.pop('Y1')\n",
    "    y1 = np.array(y1)\n",
    "    y2 = data.pop('Y2')\n",
    "    y2 = np.array(y2)\n",
    "    return y1, y2\n",
    "\n",
    "def norm(x):\n",
    "    return (x - train_stats['mean'])/ train_stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0ab089a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764886</td>\n",
       "      <td>671.315961</td>\n",
       "      <td>318.061075</td>\n",
       "      <td>176.627443</td>\n",
       "      <td>5.238599</td>\n",
       "      <td>3.482085</td>\n",
       "      <td>0.235098</td>\n",
       "      <td>2.832248</td>\n",
       "      <td>22.315694</td>\n",
       "      <td>24.534283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.106914</td>\n",
       "      <td>88.670359</td>\n",
       "      <td>42.983237</td>\n",
       "      <td>45.442208</td>\n",
       "      <td>1.751390</td>\n",
       "      <td>1.117343</td>\n",
       "      <td>0.131475</td>\n",
       "      <td>1.550520</td>\n",
       "      <td>10.070942</td>\n",
       "      <td>9.426254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>514.500000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>110.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.040000</td>\n",
       "      <td>10.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>612.500000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>686.000000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.950000</td>\n",
       "      <td>22.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31.652500</td>\n",
       "      <td>32.997500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>808.500000</td>\n",
       "      <td>416.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>43.100000</td>\n",
       "      <td>48.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1          X2          X3          X4          X5          X6  \\\n",
       "count  614.000000  614.000000  614.000000  614.000000  614.000000  614.000000   \n",
       "mean     0.764886  671.315961  318.061075  176.627443    5.238599    3.482085   \n",
       "std      0.106914   88.670359   42.983237   45.442208    1.751390    1.117343   \n",
       "min      0.620000  514.500000  245.000000  110.250000    3.500000    2.000000   \n",
       "25%      0.690000  612.500000  294.000000  122.500000    3.500000    2.250000   \n",
       "50%      0.740000  686.000000  318.500000  220.500000    3.500000    3.000000   \n",
       "75%      0.820000  735.000000  343.000000  220.500000    7.000000    4.000000   \n",
       "max      0.980000  808.500000  416.500000  220.500000    7.000000    5.000000   \n",
       "\n",
       "               X7          X8          Y1          Y2  \n",
       "count  614.000000  614.000000  614.000000  614.000000  \n",
       "mean     0.235098    2.832248   22.315694   24.534283  \n",
       "std      0.131475    1.550520   10.070942    9.426254  \n",
       "min      0.000000    0.000000    6.040000   10.900000  \n",
       "25%      0.100000    2.000000   13.000000   15.737500  \n",
       "50%      0.250000    3.000000   18.950000   22.020000  \n",
       "75%      0.400000    4.000000   31.652500   32.997500  \n",
       "max      0.400000    5.000000   43.100000   48.030000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c18186ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    614.000000\n",
       "mean      24.534283\n",
       "std        9.426254\n",
       "min       10.900000\n",
       "25%       15.737500\n",
       "50%       22.020000\n",
       "75%       32.997500\n",
       "max       48.030000\n",
       "Name: Y2, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats.pop('Y1')\n",
    "train_stats.pop('Y2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33f2cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_stats.transpose()\n",
    "train_Y = format_output(train)\n",
    "test_Y = format_output(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b7101a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "# specify the optimizer and compile the model with loss functions for both outputs\n",
    "optimizer = tf.keras.optimizers.SGD(lr = 0.001)\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = {'y1_output': 'mse', 'y2_output': 'mse'},\n",
    "              metrics = {'y1_output': tf.keras.metrics.RootMeanSquaredError(),\n",
    "                         'y2_output': tf.keras.metrics.RootMeanSquaredError()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toelt_venv",
   "language": "python",
   "name": "toelt_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
